ğŸ©º CareQuery â€” AI-Powered Healthcare Assistant (RAG + Gemini + AWS S3)

CareQuery is an end-to-end Generative AI project that helps users query healthcare-related data using a Retrieval-Augmented Generation (RAG) pipeline.
It combines AWS S3 for data storage, LangChain for document handling, ChromaDB for vector storage, and Google Gemini (via API) for intelligent response generation.

ğŸš€ Key Features

Automated Data Ingestion from AWS S3
Loads structured health data (e.g., symptomâ€“disease mappings) directly from an S3 bucket and processes it dynamically.

Embeddings + Vector Store
Generates embeddings using Google Gemini and stores them efficiently in ChromaDB for semantic retrieval.

End-to-End RAG Pipeline
Supports document ingestion â†’ embedding â†’ storage â†’ retrieval â†’ answer generation.

Dynamic File Management
Automatically checks for existing local files (s3_data/) and only downloads new/updated ones to reduce redundancy.

Portable and Cloud-Native
Works seamlessly across environments â€” local, Hugging Face Spaces, or cloud servers â€” without modification.

Interactive Interface (Streamlit)
Query health data interactively, view retrieved context, and get AI-generated responses in real-time.

ğŸ§  Project Architecture
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        AWS S3 (Data)         â”‚
            â”‚  (CSV symptom & condition)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Data Ingestion Layer         â”‚
           â”‚  (boto3 + LangChain CSVLoader)â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Embedding Layer             â”‚
           â”‚  (Google Gemini Embeddings)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Vector Store (ChromaDB)    â”‚
           â”‚ Persistent Storage: data/     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Retrieval + Generation      â”‚
           â”‚  (LangChain + Gemini LLM)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/anujpatel-ai/CareQuery.git
cd CareQuery

2ï¸âƒ£ Create Virtual Environment
python -m venv rag_pipeline
source rag_pipeline/bin/activate  # (Linux/Mac)
rag_pipeline\Scripts\activate     # (Windows)

3ï¸âƒ£ Install Requirements
pip install -r requirements.txt

4ï¸âƒ£ Add Environment Variables

Create a .env file in the project root:

GOOGLE_API_KEY = "your_google_api_key"
AWS_ACCESS_KEY_ID = "your_access_key"
AWS_SECRET_ACCESS_KEY = "your_secret_key"
AWS_REGION = "us-east-1"
S3_BUCKET_NAME = "carequery"
S3_DOWNLOADED_FILES = "s3_data/"

ğŸ§© Project Structure
ğŸ“¦ CareQuery
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_ingested.py       # Data ingestion from AWS S3
â”‚   â”œâ”€â”€ embedding_manager.py   # Embedding generation logic
â”‚   â”œâ”€â”€ vectorstore.py         # ChromaDB-based vector store
â”‚   â”œâ”€â”€ retriever.py           # Context retrieval functions
â”‚   â”œâ”€â”€ llm_pipeline.py        # Gemini-powered response generation
â”‚   â”œâ”€â”€ main.py                # Main pipeline orchestration
â”‚   â””â”€â”€ app.py                 # Streamlit app entry point
â”‚
â”œâ”€â”€ data/                      # Local persisted vector store
â”œâ”€â”€ s3_data/                   # Downloaded files from S3
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ healthcare.ipynb           # Notebook for testing pipeline

ğŸ§ª How It Works

Data Ingestion
The system fetches all .csv files from s3://carequery/ using boto3.
Files are temporarily saved to s3_data/ and loaded via LangChain CSVLoader.

Embedding Generation
Each record is converted to a vector embedding using Google Gemini embeddings.

Vector Storage
Embeddings and documents are stored in a persistent ChromaDB collection (data/).

Query Execution
On user query, the relevant context is retrieved from ChromaDB and passed to Gemini for response generation.

ğŸ’» Run the Streamlit App
streamlit run src/app.py